# Fourier-Domain Certified Robustness via Random Smoothing
Adversarial input perturbations degenerates deep learning models. In this project, utilizing the idea of "random smoothing" , we demonstrate how to turn any classifier that classifies well under Fourier-domain Gaussian noise into a new classifier that is certifiably robust to adversarial perturbations under the ℓ2 norm. We adopt Fourier-domain randomized smoothing to obtain classifiers on well-studied datasets. On both GTSRB and CIFAR-10 we achieve a certified accuracy of more than 60% with radii ≤ 4. On smaller-scale dataset (MNIST), randomized smoothing delivers even more remarkable certified accuracy.
# Final Report
Our final report can be accessed via https://pan.baidu.com/s/1VGFL-BrIBc7EKw97jo4Bzw?pwd=juea

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Import Statements Defined Here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conventionally train a LeNet-5 classifier on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), # 28*28*6\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5), # \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 14*14*6\n",
    "            # nn.Conv2d(in_channels=6, out_channels=16, kernel_size=6), # 8*8*16\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 4*4*16\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=16*4*4, out_features=120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x203bc0876f0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    'epoch': 10,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 5e-4,\n",
    "    'path': r'D:\\EricYANG\\HKUST\\22Spring\\comp5214\\project', # chage to your local path\n",
    "    'seed': 2022,\n",
    "    'perturb_norm': 1.0,\n",
    "}\n",
    "# dataset\n",
    "train_dataset = datasets.MNIST(root=args['path'], train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_dataset = datasets.MNIST(root=args['path'], train=False, transform=transforms.ToTensor(), download=False)\n",
    "# DataLoader, shuffle=True\n",
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], num_workers=0, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args['batch_size'], num_workers=0, shuffle=True)\n",
    "# put model to GPU\n",
    "model = LeNet().type(torch.FloatTensor)\n",
    "model.to(torch.device(\"cuda:0\"))\n",
    "# fix random seed\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epch, model, train_loader, test_loader):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args['learning_rate'], weight_decay=0.9)\n",
    "    BCELoss = nn.CrossEntropyLoss().type(torch.FloatTensor)\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        # put to GPU\n",
    "        data = data.to(torch.device(\"cuda:0\"))\n",
    "        target = target.to(torch.device(\"cuda:0\"))\n",
    "        optimizer.zero_grad\n",
    "        output = model(data)\n",
    "        loss = BCELoss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print('Epoch: {} \\t Training Loss: {:.6f}'.format(epch + 1, train_loss))\n",
    "    acc = test(epch, model, test_loader)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(epch, model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_loader:\n",
    "            # put to GPU\n",
    "            img = img.to(torch.device(\"cuda:0\"))\n",
    "            label = label.to(torch.device(\"cuda:0\"))\n",
    "            output = model(img)\n",
    "            _, predict = torch.max(output.data, dim=1)\n",
    "            total += label.size(0)\n",
    "            correct += (predict == label).sum().item()\n",
    "    acc = 100.0 * correct / total\n",
    "    print('Acc of epoch %d on testing: %5f %%'% (epch + 1, acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 1.208358\n",
      "Acc of epoch 1 on testing: 96.340000 %\n",
      "Epoch: 2 \t Training Loss: 0.117635\n",
      "Acc of epoch 2 on testing: 97.240000 %\n",
      "Epoch: 3 \t Training Loss: 0.095359\n",
      "Acc of epoch 3 on testing: 97.130000 %\n",
      "Epoch: 4 \t Training Loss: 0.092998\n",
      "Acc of epoch 4 on testing: 97.510000 %\n",
      "Epoch: 5 \t Training Loss: 0.087707\n",
      "Acc of epoch 5 on testing: 97.740000 %\n",
      "Epoch: 6 \t Training Loss: 0.078226\n",
      "Acc of epoch 6 on testing: 97.630000 %\n",
      "Epoch: 7 \t Training Loss: 0.067688\n",
      "Acc of epoch 7 on testing: 97.870000 %\n",
      "Epoch: 8 \t Training Loss: 0.063805\n",
      "Acc of epoch 8 on testing: 98.310000 %\n",
      "Epoch: 9 \t Training Loss: 0.064193\n",
      "Acc of epoch 9 on testing: 98.080000 %\n",
      "Epoch: 10 \t Training Loss: 0.057940\n",
      "Acc of epoch 10 on testing: 98.350000 %\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epch in range(args['epoch']):\n",
    "    acc = train(epch, model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add randomized Fourier-domain noise on a given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symmetric_pos(dims, pos):\n",
    "  # compute symmtric position of point in 2D FFT\n",
    "  x = np.array(dims)\n",
    "  p = np.array(pos)\n",
    "  return np.where(np.mod(x, 2) == 0, np.mod(x-p, x), x-1-p)\n",
    "\n",
    "\n",
    "def get_fourier_basis(x, y):\n",
    "  # compute real-valued basis vectors of 2D discrete Fourier transform\n",
    "  marker = np.zeros([x, y], dtype=np.uint8)\n",
    "  fourier_basis = np.zeros([x, y, x, y], dtype=np.float32)\n",
    "  for i in range(x):\n",
    "    for j in range(y):\n",
    "      if marker[i, j] > 0:\n",
    "        continue\n",
    "      freq = np.zeros([x, y], dtype=np.complex64)\n",
    "      sym = get_symmetric_pos((x, y), (i, j))\n",
    "      sym_i = sym[0]\n",
    "      sym_j = sym[1]\n",
    "      if (sym_i, sym_j) == (i, j):\n",
    "        freq[i, j] = 1.0\n",
    "        marker[i, j] = 1\n",
    "      else:\n",
    "        freq[i, j] = 0.5 + 0.5j\n",
    "        freq[sym_i, sym_j] = 0.5 - 0.5j\n",
    "        marker[i, j] = 1\n",
    "        marker[sym_i, sym_j] = 1\n",
    "      basis = np.fft.ifft2(np.fft.ifftshift(freq))\n",
    "      basis = np.sqrt(x * y) * np.real(basis)\n",
    "      fourier_basis[i, j, :, :] = basis\n",
    "      if (sym_i, sym_j) != (i, j):\n",
    "        fourier_basis[sym_i, sym_j, :, :] = basis\n",
    "  return fourier_basis\n",
    "\n",
    "\n",
    "def generate_perturbed_img(img, perturb_basis, perturb_norm=1.0):\n",
    "  # generate perturbed imgs given a perturbation basis\n",
    "  if len(img.shape) != 3:\n",
    "    raise ValueError('Incorrect input image shape')\n",
    "  clean_img = np.expand_dims(img, axis=3)\n",
    "  batch_size = clean_img.shape[0]\n",
    "  num_channnels = clean_img.shape[3] # MNIST num channels = 1\n",
    "  clean_img_t = np.transpose(clean_img, (0, 3, 1, 2))\n",
    "  perturb_img_t = clean_img_t + perturb_norm * perturb_basis\n",
    "  perturb_img = np.transpose(perturb_img_t, (0, 2, 3, 1))\n",
    "  return np.squeeze(perturb_img, axis=3)\n",
    "\n",
    "\n",
    "def generate_heat_map(network, img, label, pertub_norm=1.0):\n",
    "  # 1. input one image to the network, record tensor value\n",
    "  # 2. image add Fourier-basis perturbations, record tensor value\n",
    "  # 3. compare difference\n",
    "  if len(img.shape) != 3:\n",
    "    raise ValueError('Incorrect input image shape')\n",
    "  num_channnels = img.shape[0] # MNIST num channels = 1\n",
    "  height = img.shape[1]\n",
    "  width = img.shape[2]\n",
    "  basis = get_fourier_basis(height, width)\n",
    "\n",
    "  # evaluate over all frequency basis\n",
    "  for i in range(height):\n",
    "    for j in range(width):\n",
    "      perturb_img = generate_perturbed_img(img, basis[i, j, Ellipsis], pertub_norm)\n",
    "      tensor_pb = torch.from_numpy(perturb_img).to(torch.device(\"cuda:0\")).unsqueeze(dim=0)\n",
    "      label = label.to(torch.device(\"cuda:0\"))\n",
    "      print(type(tensor_pb), tensor_pb.shape, type(label), label)\n",
    "      output = network(tensor_pb)\n",
    "      _, predict = torch.max(output.data, dim=1)\n",
    "      print(predict)\n",
    "    #   break\n",
    "    # break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1, 28, 28) <class 'torch.Tensor'> tensor(6)\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 28, 28]) <class 'torch.Tensor'> tensor(6, device='cuda:0')\n",
      "tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "fourier_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=True)\n",
    "sample_img, sample_label = None, None\n",
    "\n",
    "# select random img from test dataset for fourier pertubation\n",
    "for imgs, label in fourier_loader:\n",
    "    sample_img = imgs[0].numpy()\n",
    "    sample_label = label[0]\n",
    "    break\n",
    "\n",
    "print(type(sample_img), sample_img.shape, type(sample_label), sample_label)\n",
    "generate_heat_map(model, sample_img, sample_label, args['perturb_norm'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
